---
---

@inproceedings{liu2025metascale,
  title={Metascale: Test-time scaling with evolving meta-thoughts},
  author={Liu, Qin and Zhou, Wenxuan and Xu, Nan and Huang, James Y and Wang, Fei and Zhang, Sheng and Poon, Hoifung and Chen, Muhao},
  arxiv={2503.13447},
  year={2025},
  booktitle={arXiv preprint},
  abbr={preprint}
}

@inproceedings{liu2025vlm,
  title={VLM-Guard: Safeguarding Vision-Language Models via Fulfilling Safety Alignment Gap},
  author={Liu, Qin and Wang, Fei and Xiao, Chaowei and Chen, Muhao},
  arxiv={2502.10486},
  year={2025},
  booktitle={arXiv preprint},
  abbr={preprint}
}

@inproceedings{lin2025survey,
  title={A survey on mechanistic interpretability for multi-modal foundation models},
  author={Lin, Zihao and Basu, Samyadeep and Beigi, Mohammad and Manjunatha, Varun and Rossi, Ryan A and Wang, Zichao and Zhou, Yufan and Balasubramanian, Sriram and Zarei, Arman and Rezaei, Keivan and others},
  arxiv={2502.17516},
  year={2025},
  booktitle={arXiv preprint},
  abbr={preprint}
}

@inproceedings{liu2024sudolmlearningaccesscontrol,
  title={SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment}, 
  author={Qin Liu and Fei Wang and Chaowei Xiao and Muhao Chen},
  year={2024},
  arxiv={2410.14676},
  booktitle={arXiv preprint},
  abbr={preprint}
}

@inproceedings{liu2024unraveling,
  title={Unraveling and Mitigating Safety Alignment Degradation of Vision-Language Models},
  author={Liu, Qin and Shang, Chao and Liu, Ling and Pappas, Nikolaos and Ma, Jie and John, Neha Anna and Doss, Srikanth and Marquez, Lluis and Ballesteros, Miguel and Benajiba, Yassine},
  booktitle={arXiv preprint},
  arxiv={2410.09047},
  year={2024},
  abbr={preprint}
}

@inproceedings{zhu2024unraveling,
  title={Unraveling Cross-modality Knowledge Conflict in Large Vision-Language Models},
  author={Zhu, Tinghui and Liu, Qin and Wang, Fei and Tu, Zhengzhong and Chen, Muhao},
  booktitle={arXiv preprint},
  arxiv={2410.03659},
  year={2024},
  abbr={preprint}
}

@inproceedings{xi2023risepotentiallargelanguage,
  title={The Rise and Potential of Large Language Model Based Agents: A Survey}, 
  author={Zhiheng Xi and Wenxiang Chen and Xin Guo and others},
  booktitle={arXiv preprint},
  year={2023},
  arxiv={2309.07864},
  abbr={preprint}
}

@inproceedings{jung2024familiarity,
  title={Familiarity-aware evidence compression for retrieval augmented generation},
  author={Jung, Dongwon and Liu, Qin and Huang, Tenghao and Zhou, Ben and Chen, Muhao},
  arxiv={2409.12468},
  year={2024},
  abbr={preprint},
  booktitle={arXiv preprint}
}

@inproceedings{zheng2023secrets,
  title={Secrets of RLHF in Large Language Models Part I: PPO},
  author={Zheng, Rui and Dou, Shihan and Gao, Songyang and Shen, Wei and Wang, Binghai and Liu, Yan and Jin, Senjie and Liu, Qin and Xiong, Limao and Chen, Lu and others},
  booktitle={arXiv preprint},
  year={2023},
  arxiv={2307.04964},
  abbr={preprint}
}

@inproceedings{mo2023test,
  title={Test-time Backdoor Mitigation for Black-box Large Language Models with Defensive Demonstrations},
  author={Mo, Wenjie and Xu, Jiashu and Liu, Qin and Wang, Jiongxiao and Yan, Jun and Xiao, Chaowei and Chen, Muhao},
  booktitle={Findings of NAACL},
  year={2025},
  arxiv={2311.09763},
  abbr={NAACL}
}

@inproceedings{qi2024metascientist,
  title={MetaScientist: A Human-AI Synergistic Framework for Automated Mechanical Metamaterial Design},
  author={Qi, Jingyuan and Jia, Zian and Liu, Minqian and Zhan, Wangzhi and Zhang, Junkai and Wen, Xiaofei and Gan, Jingru and Chen, Jianpeng and Liu, Qin and Ma, Mingyu Derek and others},
  booktitle={Proceedings of NAACL: System Demonstrations},  
  arxiv={2412.16270},
  year={2025},
  abbr={NAACL Demo}
}

@inproceedings{wang2025muirbench,
  title={MuirBench: A Comprehensive Benchmark for Robust Multi-image Understanding},
  author={Fei Wang and Xingyu Fu and James Y. Huang and Zekun Li and Qin Liu and Xiaogeng Liu and Mingyu Derek Ma and Nan Xu and Wenxuan Zhou and Kai Zhang and Tianyi Lorena Yan and Wenjie Jacky Mo and Hsiang-Hui Liu and Pan Lu and Chunyuan Li and Chaowei Xiao and Kai-Wei Chang and Dan Roth and Sheng Zhang and Hoifung Poon and Muhao Chen},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025},
  html={https://openreview.net/forum?id=TrVYEZtSQH},
  arxiv={2406.09411},
  abbr={ICLR}
}

@inproceedings{liu2024mitigating,
  title={Mitigating Backdoor Threats to Large Language Models: Advancement and Challenges},
  author={Liu, Qin and Mo, Wenjie and Tong, Terry and Xu, Jiashu and Wang, Fei and Xiao, Chaowei and Chen, Muhao},
  booktitle={Allerton Conference},
  year={2024},
  arxiv={2409.19993},
  abbr={Allerton}
}

@inproceedings{du2024llms,
  title={LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing},
  author={Du, Jiangshu and Wang, Yibo and Zhao, Wenting and Deng, Zhongfen and Liu, Shuaiqi and Lou, Renze and Zou, Henry Peng and Venkit, Pranav Narayanan and Zhang, Nan and Srinath, Mukund and others},
  booktitle={Proceedings of EMNLP},
  year={2024},
  arxiv={2406.16253},
  abbr={EMNLP}
}

@inproceedings{tong2024securing,
  title={Securing Multi-turn Conversational Language Models Against Distributed Backdoor Triggers},
  author={Tong, Terry and Xu, Jiashu and Liu, Qin and Chen, Muhao},
  booktitle={Findings of EMNLP},
  arxiv={2407.04151},
  year={2024},
  abbr={EMNLP}
}

@inproceedings{liu2024monotonic,
      title={Monotonic Paraphrasing Improves Generalization of Language Model Prompting}, 
      author={Qin Liu and Fei Wang and Nan Xu and Tianyi Yan and Tao Meng and Muhao Chen},
      booktitle={Findings of EMNLP},
      year={2024},
      arxiv={2403.16038},
      abbr={EMNLP}
}


@inproceedings{graf2024two,
      title={Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors}, 
      author={Graf, Victoria and Liu, Qin and Chen, Muhao},
      booktitle={Proceedings of NAACL},
      year={2024},
      arxiv={2404.02356},
      html={https://aclanthology.org/2024.naacl-long.40},
      pages={706--718},
      abbr={NAACL},
}


@inproceedings{liu2023shortcuts,
      title={From Shortcuts to Triggers: Backdoor Defense with Denoised PoE}, 
      author={Qin Liu and Fei Wang and Chaowei Xiao and Muhao Chen},
      year={2024},
      arxiv={2305.14910},
      booktitle={Proceedings of NAACL},
      abbr={NAACL},
      html={https://aclanthology.org/2024.naacl-long.27},
      pages={483--496},
      abstract={Language models are often at risk of diverse backdoor attacks, especially data poisoning. Thus, it is important to investigate defense solutions for addressing them. Existing backdoor defense methods mainly focus on backdoor attacks with explicit triggers, leaving a universal defense against various backdoor attacks with diverse triggers largely unexplored. In this paper, we propose an end-to-end ensemble-based backdoor defense framework, DPoE (Denoised Product-of-Experts), which is inspired by the shortcut nature of backdoor attacks, to defend various backdoor attacks. DPoE consists of two models: a shallow model that captures the backdoor shortcuts and a main model that is prevented from learning the shortcuts. To address the label flip caused by backdoor attackers, DPoE incorporates a denoising design. Experiments on three NLP tasks show that DPoE significantly improves the defense performance against various types of backdoor triggers including word-level, sentence-level, and syntactic triggers. Furthermore, DPoE is also effective under a more challenging but practical setting that mixes multiple types of triggers.},
      code={https://github.com/luka-group/DPoE},
      selected={false}
}



@inproceedings{zheng2023detecting,
      title={Detecting Adversarial Samples through Sharpness of Loss Landscape},
      author={Zheng, Rui and Dou, Shihan and Zhou, Yuhao and Liu, Qin and Gui, Tao and Zhang, Qi and Wei, Zhongyu and Huang, Xuan-Jing and Zhang, Menghan},
      booktitle={Findings of ACL},
      pages={11282--11298},
      year={2023},
      abbr={ACL},
      html={https://aclanthology.org/2023.findings-acl.717/},
      selected={false}
}

@inproceedings{zheng2023characterizing,
      title={Characterizing the Impacts of Instances on Robustness},
      author={Zheng, Rui and Xi, Zhiheng and Liu, Qin and Lai, Wenbin and Gui, Tao and Zhang, Qi and Huang, Xuan-Jing and Ma, Jin and Shan, Ying and Ge, Weifeng},
      booktitle={Findings of ACL},
      pages={2314--2332},
      year={2023},
      abbr={ACL},
      selected={false},
      html={https://aclanthology.org/2023.findings-acl.146/}
}

@inproceedings{liu2022flooding,
      title={Flooding-X: Improving BERTâ€™s resistance to adversarial attacks via loss-restricted fine-tuning},
      author={Liu*, Qin and Zheng*, Rui and Rong, Bao and Liu, Jingyi and Liu, Zhihua and Cheng, Zhanzhan and Qiao, Liang and Gui, Tao and Zhang, Qi and Huang, Xuan-Jing},
      booktitle={Proceedings of ACL},
      pages={5634--5644},
      year={2022},
      abbr={ACL},
      selected={false},
      html={https://aclanthology.org/2022.acl-long.386/},
      code={https://github.com/qinliu9/Flooding-X},
      abstract={Adversarial robustness has attracted much attention recently, and the mainstream solution is adversarial training. However, the tradition of generating adversarial perturbations for each input embedding (in the settings of NLP) scales up the training computational complexity by the number of gradient steps it takes to obtain the adversarial samples. To address this problem, we leverage Flooding method which primarily aims at better generalization and we find promising in defending adversarial attacks. We further propose an effective criterion to bring hyper-parameter-dependent flooding into effect with a narrowed-down search space by measuring how the gradient steps taken within one epoch affect the loss of each batch. Our approach requires zero adversarial sample for training, and its time consumption is equivalent to fine-tuning, which can be 2-15 times faster than standard adversarial training. We experimentally show that our method improves BERTâ€™s resistance to textual adversarial attacks by a large margin, and achieves state-of-the-art robust accuracy on various text classification and GLUE tasks.}
}

@inproceedings{zheng2022plugat,
      title = {PlugAT: A Plug and Play Module to Defend against Textual Adversarial Attack},
      author = {Zheng, Rui  and Bao, Rong and Liu, Qin and Gui, Tao and Zhang, Qi and Huang, Xuanjing and Xie, Rui and Wu, Wei},
      booktitle = {Proceedings of COLING},
      year = {2022},
      pages = {2873--2882},
      abbr={COLING},
      selected={false},
      html={https://aclanthology.org/2022.coling-1.253/}
}

@inproceedings{wang2021textflint,
  title={Textflint: Unified multilingual robustness evaluation toolkit for natural language processing},
  author={Wang*, Xiao and Liu*, Qin and Gui, Tao and Zhang, Qi and Zou, Yicheng and Zhou, Xin and Ye, Jiacheng and Zhang, Yongxin and Zheng, Rui and Pang, Zexiong and others},
  booktitle={Proceedings of ACL: System Demonstrations},
  pages={347--355},
  year={2021},
abbr={ACL Demo},
selected={false},
html={https://aclanthology.org/2021.acl-demo.41/},
abstract={TextFlint is a multilingual robustness evaluation toolkit for NLP tasks that incorporates universal text transformation, task-specific transformation, adversarial attack, subpopulation, and their combinations to provide comprehensive robustness analyses. This enables practitioners to automatically evaluate their models from various aspects or to customize their evaluations as desired with just a few lines of code. TextFlint also generates complete analytical reports as well as targeted augmented data to address the shortcomings of the model in terms of its robustness. To guarantee acceptability, all the text transformations are linguistically based and all the transformed data selected (up to 100,000 texts) scored highly under human evaluation. To validate the utility, we performed large-scale empirical evaluations (over 67,000) on state-of-the-art deep learning models, classic supervised methods, and real-world systems. The toolkit is already available at https://github.com/textflint with all the evaluation results demonstrated at textflint.io.},
code={https://github.com/textflint}
}

@inproceedings{xing2020learning,
  title={Learning to generate representations for novel words: Mimic the OOV situation in training},
  author={Xing, Xiaoyu and Peng, Minlong and Zhang, Qi and Liu, Qin and Huang, Xuanjing},
  booktitle={NLPCC},
  pages={321--332},
  year={2020},
  organization={Springer},
selected={false},
abbr={NLPCC}
}
